{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import music21 as m21\n",
    "import os\n",
    "import json\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "PIANO_DATAPATH = \"Dataset\"\n",
    "MUSIC_DURATION = 0.25\n",
    "SAVE_MUSIC_PATH = \"Processed_data\"\n",
    "SEQUENCE_LENGTH = 128\n",
    "SINGLE_FILE_PATH = \"single_file_dataset.txt\"\n",
    "MAPPING_PATH = \"Mapping.json\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(data_path):\n",
    "    songs = []\n",
    "\n",
    "    for path, _, filenames in os.walk(data_path):\n",
    "\n",
    "        for file in filenames:\n",
    "            if file.endswith(\"mid\"):\n",
    "                song = m21.converter.parse(os.path.join(path, file))\n",
    "                # Take just the melody of the song\n",
    "                song = song.getElementsByClass(m21.stream.Part)\n",
    "                songs.append(song[0])\n",
    "\n",
    "    return songs\n",
    "\n",
    "songs = load_data(PIANO_DATAPATH)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_songs(song, time_step=0.25):\n",
    "    # For each song, need to grab the notes and rest, flatten the list and song object \n",
    "    encoded_melody = []\n",
    "    encoded_chords = []\n",
    "    \n",
    "    for element in song.flat.notesAndRests:\n",
    "        \n",
    "         # handle notes\n",
    "        if isinstance(element, m21.note.Note):\n",
    "            symbol = element.pitch.midi # 60\n",
    "        # handle rests\n",
    "        elif isinstance(element, m21.note.Rest):\n",
    "            symbol = \"r\"\n",
    "        elif isinstance(element, m21.chord.Chord):\n",
    "            continue\n",
    "\n",
    "        # convert the note/rest into time series notation\n",
    "        steps = int(element.duration.quarterLength / time_step)\n",
    "        for step in range(steps):\n",
    "            \n",
    "            # if it's the first time we see a note/rest, let's encode it. Otherwise, it means we're carrying the same\n",
    "            # symbol in a new time step\n",
    "            if step == 0:\n",
    "                encoded_melody.append(symbol)\n",
    "            else:\n",
    "                encoded_melody.append(\"_\")\n",
    "                encoded_chords.append(\"_\")\n",
    "\n",
    "    # cast encoded song to str\n",
    "    encoded_melody = \" \".join(map(str, encoded_melody))\n",
    "    \n",
    "\n",
    "    return encoded_melody\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Sam\\anaconda3\\envs\\Music_gen_WS\\lib\\site-packages\\music21\\stream\\base.py:3694: Music21DeprecationWarning: .flat is deprecated.  Call .flatten() instead\n",
      "  return self.iter().getElementsByClass(classFilterList)\n"
     ]
    }
   ],
   "source": [
    "def preprocess(data_path):\n",
    "    \n",
    "    # Load the songs:\n",
    "    songs = load_data(data_path)\n",
    "\n",
    "    for i, song in enumerate(songs):\n",
    "\n",
    "        # Encode the song\n",
    "        encoded_mel = encode_songs(song)\n",
    "\n",
    "        # Create the filename from the directory and name for each song\n",
    "        save_dir_mel = os.path.join(SAVE_MUSIC_PATH, str(i) + \".txt\")\n",
    "        \n",
    "        # Write to the new file\n",
    "        with open(save_dir_mel, \"w\") as fp:\n",
    "            fp.write(encoded_mel)\n",
    "\n",
    "    fp.close()\n",
    "\n",
    "\n",
    "preprocess(PIANO_DATAPATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load(file_path):\n",
    "    with open(file_path, \"r\") as fp:\n",
    "        song = fp.read()\n",
    "    return song"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "263\n"
     ]
    }
   ],
   "source": [
    "def create_single_file(dataset_path, single_file_path, sequence_length):\n",
    "    \"\"\" \n",
    "    Generates mappings for each individual element in the song\n",
    "    \"\"\"\n",
    "\n",
    "    new_song_delimiter = \"/ \" * sequence_length\n",
    "    songs = \"\"\n",
    "    \n",
    "    # Load the data into a single string with the delimiter\n",
    "    for path, subdir, files in os.walk(dataset_path):\n",
    "\n",
    "        for file in files:\n",
    "            \n",
    "            file_path = os.path.join(path, file)\n",
    "\n",
    "            song = load(file_path)\n",
    "            \n",
    "            songs = songs + \"\".join(song) + \" \" + new_song_delimiter\n",
    "\n",
    "    # remove empty space from last character of string\n",
    "    songs = songs[:-1]\n",
    "    \n",
    "    # save string that contains all the dataset\n",
    "    with open(single_file_path, \"w\") as fp:\n",
    "        fp.write(songs)\n",
    "\n",
    "    return songs# remove empty space from last character of string\n",
    "\n",
    "songs = create_single_file(SAVE_MUSIC_PATH, SINGLE_FILE_PATH, 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_mapping(songs, mapping_path):\n",
    "    \"\"\"Creates a json file that maps the symbols in the song dataset onto integers\n",
    "\n",
    "    :param songs (str): String with all songs\n",
    "    :param mapping_path (str): Path where to save mapping\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    mappings = {}\n",
    "\n",
    "    # identify the vocabulary\n",
    "    songs = songs.split()\n",
    "    vocabulary = list(set(songs))\n",
    "\n",
    "    # create mappings\n",
    "    for i, symbol in enumerate(vocabulary):\n",
    "        mappings[symbol] = i\n",
    "\n",
    "    # save voabulary to a json file\n",
    "    with open(mapping_path, \"w\") as fp:\n",
    "        json.dump(mappings, fp, indent=4)\n",
    "\n",
    "create_mapping(songs, MAPPING_PATH)\n",
    "\n",
    "def convert_songs_to_int(songs):\n",
    "    int_songs = []\n",
    "\n",
    "    # load mappings\n",
    "    with open(MAPPING_PATH, \"r\") as fp:\n",
    "        mappings = json.load(fp)\n",
    "\n",
    "    # transform songs string to list\n",
    "    songs = songs.split()\n",
    "\n",
    "    # map songs to int\n",
    "    for symbol in songs:\n",
    "        int_songs.append(mappings[symbol])\n",
    "\n",
    "    return int_songs\n",
    "\n",
    "ints = convert_songs_to_int(songs)\n",
    "\n",
    "\n",
    "def generate_training_sequences(sequence_length):\n",
    "    \"\"\"Create input and output data samples for training. Each sample is a sequence.\n",
    "\n",
    "    :param sequence_length (int): Length of each sequence. With a quantisation at 16th notes, 64 notes equates to 4 bars\n",
    "\n",
    "    :return inputs (ndarray): Training inputs\n",
    "    :return targets (ndarray): Training targets\n",
    "    \"\"\"\n",
    "\n",
    "    # load songs and map them to int\n",
    "    songs = load(SINGLE_FILE_PATH)\n",
    "    int_songs = convert_songs_to_int(songs)\n",
    "\n",
    "    inputs = []\n",
    "    targets = []\n",
    "\n",
    "    # generate the training sequences\n",
    "    num_sequences = len(int_songs) - sequence_length\n",
    "    for i in range(num_sequences):\n",
    "        inputs.append(int_songs[i:i+sequence_length])\n",
    "        targets.append(int_songs[i+sequence_length])\n",
    "\n",
    "    # one-hot encode the sequences\n",
    "    vocabulary_size = len(set(int_songs))\n",
    "    # inputs size: (# of sequences, sequence length, vocabulary size)\n",
    "    inputs = keras.utils.to_categorical(inputs, num_classes=vocabulary_size)\n",
    "    targets = np.array(targets)\n",
    "\n",
    "    print(f\"There are {len(inputs)} sequences.\")\n",
    "\n",
    "    return inputs, targets\n",
    "\n",
    "inputs, targets = generate_training_sequences(128)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

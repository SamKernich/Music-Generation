{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import music21\n",
    "import matplotlib as plt\n",
    "import torchvision.utils as vutils\n",
    "\n",
    "import torch.backends.cudnn as cudnn\n",
    "torch.cuda.empty_cache()\n",
    "cudnn.benchmark = True  # Optimise for hardware\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 16\n",
    "EPOCHS = 400\n",
    "NOISE_DIM= 100\n",
    "NUM_CLASSES = 18\n",
    "BETA1 = 0.5 # Hyperparamter for adam optimizer\n",
    "LR = 0.004 # Might need to adjust\n",
    "EMBEDDING_DIM = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "\n",
    "        # Embedding for the labels (num_classes = 18 for each composer)\n",
    "        self.label_emb = nn.Embedding(NUM_CLASSES, EMBEDDING_DIM)  # (N, 50)\n",
    "\n",
    "        # Dense layer for the label embedding\n",
    "        self.fc_label = nn.Linear(EMBEDDING_DIM, 8 * 16)  # (N, 128) for reshaping to 8x16\n",
    "\n",
    "        # Dense layer for the latent noise input\n",
    "        self.fc_noise = nn.Linear(NOISE_DIM, 128 * 8 * 16)  # (N, 128 * 8 * 16)\n",
    "\n",
    "        # ConvTranspose layers for upsampling\n",
    "        self.conv1 = nn.ConvTranspose2d(129, 128, kernel_size=4, stride=2, padding=1)  # Upsample to 16x32\n",
    "        self.conv2 = nn.ConvTranspose2d(128, 64, kernel_size=4, stride=2, padding=1)   # Upsample to 32x64\n",
    "        self.conv3 = nn.ConvTranspose2d(64, 32, kernel_size=4, stride=2, padding=1)    # Upsample to 64x128\n",
    "        self.conv4 = nn.ConvTranspose2d(32, 1, kernel_size=4, stride=2, padding=1)     # Upsample to 128x256\n",
    "\n",
    "        # LeakyReLU activation function\n",
    "        self.activation = nn.ReLU(0.2)\n",
    "        self.batch_norm = nn.BatchNorm2d()\n",
    "        self.tanh_layer = nn.Tanh()\n",
    "\n",
    "    def forward(self, noise, labels):\n",
    "        # Step 1: Embed the labels\n",
    "        label_embedding = self.label_emb(labels)  # (N, 50)\n",
    "        label_embedding = self.fc_label(label_embedding)  # (N, 128)\n",
    "        label_embedding = label_embedding.view(-1, 8, 16, 1)  # Reshape to (N, 8, 16, 1)\n",
    "\n",
    "        # Step 2: Process the latent noise input through a dense layer\n",
    "        noise_embedding = self.fc_noise(noise)  # (N, 128 * 8 * 16)\n",
    "        \n",
    "        noise_embedding = self.activation(noise_embedding)  # Apply LeakyReLU\n",
    "        noise_embedding = noise_embedding.view(-1, 128, 8, 16)  # Reshape to (N, 128, 8, 16)\n",
    "\n",
    "        # Step 3: Concatenate the noise and label embeddings along the channel axis\n",
    "        x = torch.cat((noise_embedding, label_embedding.permute(0, 3, 1, 2)), dim=1)  # (N, 129, 8, 16)\n",
    "\n",
    "        # Step 4: Upsample to 16x32\n",
    "        x = self.conv1(x)  # (N, 128, 16, 32)\n",
    "        x = self.activation(x)\n",
    "\n",
    "        # Step 5: Upsample to 32x64\n",
    "        x = self.conv2(x)  # (N, 64, 32, 64)\n",
    "        x = self.activation(x)\n",
    "\n",
    "        # Step 6: Upsample to 64x128\n",
    "        x = self.conv3(x)  # (N, 32, 64, 128)\n",
    "        x = self.activation(x)\n",
    "\n",
    "        # Step 7: Upsample to 128x256\n",
    "        out = self.conv4(x)  # (N, 1, 128, 256)\n",
    "        x = self.tanh_layer(out)\n",
    "\n",
    "         # Step 9: Apply thresholding to get binary output (0 or 1)\n",
    "        #out_binary = (out > 0.5).float()  # Convert to 0 or 1\n",
    "\n",
    "        return x #out_binary\n",
    "\n",
    "\"\"\"\n",
    "# Instantiate the model\n",
    "latent_dim = 100\n",
    "num_classes = 10\n",
    "model = Generator()\n",
    "\n",
    "# Example input (noise and labels)\n",
    "batch_size = 1\n",
    "noise = torch.randn(batch_size, latent_dim)  # (N, latent_dim)\n",
    "labels = torch.randint(0, num_classes, (batch_size,))  # (N,)\n",
    "\n",
    "# Forward pass\n",
    "output = model(noise, labels)\n",
    "print(output.shape)  # Should be (batch_size, 1, 128, 256)\n",
    "\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "\n",
    "        # Define the embedding layer separately\n",
    "        self.label_conditioned_generator = nn.Embedding(NUM_CLASSES, EMBEDDING_DIM)\n",
    "        \n",
    "        self.latent = nn.Sequential(\n",
    "            nn.Linear(NOISE_DIM, 4 * 8 * 512),\n",
    "            nn.LeakyReLU(0.2, inplace=True)\n",
    "        )\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            nn.ConvTranspose2d(512 + 1, 64 * 8, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(64 * 8, momentum=0.1, eps=0.8),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(64 * 8, 64 * 4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(64 * 4, momentum=0.1, eps=0.8),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(64 * 4, 64 * 2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(64 * 2, momentum=0.1, eps=0.8),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(64 * 2, 64 * 1, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(64 * 1, momentum=0.1, eps=0.8),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(64 * 1, 1, 4, 2, 1, bias=False),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        noise_vector, label = inputs\n",
    "        label_output = self.label_conditioned_generator(label)\n",
    "        label_output = label_output.view(-1, 1, 4, 8)\n",
    "        latent_output = self.latent(noise_vector)\n",
    "        latent_output = latent_output.view(-1, 512, 4, 8)\n",
    "        concat = torch.cat((latent_output, label_output), dim=1)\n",
    "        image = self.model(concat)\n",
    "        return image\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, in_shape=(1, 128, 256), num_classes=NUM_CLASSES):\n",
    "        super(Discriminator, self).__init__()\n",
    "        \n",
    "        # Embedding for labels\n",
    "        self.label_emb = nn.Embedding(num_classes, EMBEDDING_DIM)  # (N, 50)\n",
    "        \n",
    "        # Fully connected layer for label embedding, to match pianoroll matrix size\n",
    "        self.fc_label = nn.Linear(EMBEDDING_DIM, in_shape[1] * in_shape[2])  # (N, 128 * 256)\n",
    "        \n",
    "        # Convolutional layers for processing the concatenated image and label\n",
    "        self.conv1 = nn.Conv2d(2, 128, kernel_size=3, stride=2, padding=1)  # (N, 128, 64, 128)\n",
    "        self.conv2 = nn.Conv2d(128, 128, kernel_size=3, stride=2, padding=1)  # (N, 128, 32, 64)\n",
    "        \n",
    "        # Dropout layer for regularization\n",
    "        self.dropout = nn.Dropout(0.4)\n",
    "        \n",
    "        # Fully connected output layer\n",
    "        self.fc = nn.Linear(128 * 32 * 64, 1)\n",
    "        \n",
    "        # Sigmoid activation function\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, img, labels):\n",
    "        # Step 1: Embed the labels\n",
    "        label_embedding = self.label_emb(labels)  # (N, 50)\n",
    "        \n",
    "        # Step 2: Process label embedding through a dense layer to match image dimensions\n",
    "        label_embedding = self.fc_label(label_embedding)  # (N, 128 * 256)\n",
    "        \n",
    "        # Step 3: Reshape label embedding to add as a channel to the image\n",
    "        label_embedding = label_embedding.view(-1, 1, 128, 256)  # Reshape to (N, 1, 128, 256)\n",
    "        \n",
    "        # Step 4: Concatenate the label embedding with the image input\n",
    "        x = torch.cat((img, label_embedding), dim=1)  # Concatenate along channel dimension: (N, 2, 128, 256)\n",
    "        \n",
    "        # Step 5: Apply convolutional layers to process the image and label\n",
    "        x = nn.LeakyReLU(0.2)(self.conv1(x))  # (N, 128, 64, 128)\n",
    "       \n",
    "        x = nn.LeakyReLU(0.2)(self.conv2(x))  # (N, 128, 32, 64)\n",
    "        \n",
    "        # Step 6: Flatten the feature maps\n",
    "        x = x.view(x.size(0), -1)  # (N, 128 * 32 * 64 = 262144)\n",
    "        \n",
    "        # Step 7: Apply dropout for regularization\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        # Step 8: Fully connected layer and sigmoid activation for binary classification\n",
    "        out = self.fc(x)  # (N, 1)\n",
    "        out = self.sigmoid(out)  # Sigmoid activation to get values between 0 and 1\n",
    "        \n",
    "        return out\n",
    "\n",
    "\n",
    "# Instantiate the discriminator\n",
    "discriminator = Discriminator(in_shape=(1, 128, 256), num_classes=10)\n",
    "\n",
    "\n",
    "# Example inputs: random image and label\n",
    "batch_size = 1\n",
    "output = torch.randn(batch_size, 1, 128, 256)  # Random image input\n",
    "labels = torch.randint(0, 10, (batch_size,))  # Random labels (10 classes)\n",
    "\n",
    "\n",
    "# Forward pass\n",
    "output1 = discriminator(output, labels)\n",
    "\n",
    "print(output.shape)  # Output should be (batch_size, 1)\n",
    "print(output1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "inputs_seq = torch.load(\"Input_tensors.pt\")\n",
    "labels_seq = torch.load(\"Labels_tensors.pt\")\n",
    "dataset = TensorDataset(inputs_seq, labels_seq)\n",
    "\n",
    "#Split into batches\n",
    "batch_size = 16\n",
    "dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "# Check that the data is loaded correctly\n",
    "print(\"Number of input pianorolls: \", len(dataset))\n",
    "\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom weights initialization called on ``netG`` and ``netD``\n",
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "        nn.init.constant_(m.bias.data, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Send the models to the GPU\n",
    "netG = Generator().to(device)\n",
    "netD = Discriminator().to(device)\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "# Initialize the labels\n",
    "real_label = 0.9\n",
    "fake_label = 0\n",
    "\n",
    "fixed_noise = torch.randn(BATCH_SIZE, NOISE_DIM,  device=device)\n",
    "\n",
    "# Define the optimizers\n",
    "optimizerG = optim.Adam(netG.parameters(), lr=LR, betas=(BETA1, 0.999))\n",
    "optimizerD = optim.Adam(netD.parameters(), lr=LR, betas=(BETA1, 0.999))\n",
    "\n",
    "# Apply the randomly initialized weights to the discriminator and generator models.\n",
    "netG.apply(weights_init)\n",
    "netD.apply(weights_init)\n",
    "\n",
    "print(\"Generator model: \", netG)\n",
    "print(\"Discriminator model: \", netD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Lists to keep track of progress\n",
    "output_list = []\n",
    "G_losses = []\n",
    "D_losses = []\n",
    "iters = 0\n",
    "\n",
    "num_epochs = 10\n",
    "\n",
    "\"\"\" \n",
    "Data is being loaded correctly. For some reason, model keeps blowing up and not fucking working. D(x)should start close to 1 (predicting everything as real) before settling around 0.5\n",
    "D(g(z)) should start around 0 (everything should be picked as fake) before sitting at 0.5.\n",
    "\n",
    "This means the discriminator can't determine which is real and which is fake, so generator has been trained sufficiently.\n",
    "\n",
    "I think this could be errors in the data or data normalization process\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "print(\"Starting Training Loop...\")\n",
    "# For each epoch\n",
    "for epoch in range(num_epochs):\n",
    "    # For each batch in the dataloader\n",
    "    for i, data in enumerate(dataloader):\n",
    "        \n",
    "        ##########\n",
    "        # (1) Update D network: maximize log(D(x)) + log(1 - D(G(z)))\n",
    "        ###########################\n",
    "        ## Train with all-real batch\n",
    "        netD.zero_grad()\n",
    "        # Format batch\n",
    "        real_cpu = data[0].to(device).float()   # ensure tensor is float32\n",
    "        real_cpu = real_cpu.unsqueeze(1)\n",
    "        \n",
    "        b_size = real_cpu.size(0)\n",
    "        \n",
    "        if b_size != BATCH_SIZE:\n",
    "            print(f\"Skipping batch {i} due to insufficient size: {b_size}\")\n",
    "            continue\n",
    "        \n",
    "        real_label_from_data = data[1].to(device).int()     # Generator and discriminator expect integer labels\n",
    "        \n",
    "        # Creates a label tensor of 1s to pass to loss function\n",
    "        label = torch.full((b_size,), real_label, dtype=torch.float, device=device)\n",
    "        \n",
    "        # Forward pass real batch through D\n",
    "        output = netD(real_cpu, real_label_from_data).view(-1)\n",
    "        \n",
    "        # Calculate loss on all-real batch\n",
    "        errD_real = criterion(output, label)\n",
    "        # Calculate gradients for D in backward pass\n",
    "        errD_real.backward()\n",
    "        D_x = output.mean().item()\n",
    "\n",
    "        ## Train with all-fake batch\n",
    "        # Generate batch of latent vectors\n",
    "        noise = torch.randn(b_size, NOISE_DIM, dtype=torch.float, device=device)\n",
    "\n",
    "        # Generate fake image batch with G\n",
    "        fake = netG(noise, real_label_from_data)\n",
    "        label.fill_(fake_label)\n",
    "        # Classify all fake batch with D\n",
    "        output = netD(fake.detach(), real_label_from_data).view(-1)\n",
    "        # Calculate D's loss on the all-fake batch\n",
    "        errD_fake = criterion(output, label)\n",
    "        # Calculate the gradients for this batch, accumulated (summed) with previous gradients\n",
    "        errD_fake.backward()\n",
    "        D_G_z1 = output.mean().item()\n",
    "        # Compute error of D as sum over the fake and the real batches\n",
    "        errD = errD_real + errD_fake\n",
    "        # Update D\n",
    "        optimizerD.step()\n",
    "\n",
    "        ############################\n",
    "        # (2) Update G network: maximize log(D(G(z)))\n",
    "        ###########################\n",
    "        netG.zero_grad()\n",
    "        label.fill_(real_label)  # fake labels are real for generator cost\n",
    "        # Since we just updated D, perform another forward pass of all-fake batch through D\n",
    "        output = netD(fake, real_label_from_data).view(-1)\n",
    "        # Calculate G's loss based on this output\n",
    "        errG = criterion(output, label)\n",
    "        # Calculate gradients for G\n",
    "        errG.backward()\n",
    "        D_G_z2 = output.mean().item()\n",
    "        # Update G\n",
    "        optimizerG.step()\n",
    "\n",
    "        # Output training stats\n",
    "        if i % 2 == 0:\n",
    "            print('[%d/%d][%d/%d]\\tLoss_D: %.4f\\tLoss_G: %.4f\\tD(x): %.4f\\tD(G(z)): %.4f / %.4f'\n",
    "                  % (epoch, num_epochs, i, len(dataloader),\n",
    "                     errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))\n",
    "\n",
    "        # Save Losses for plotting later\n",
    "        G_losses.append(errG.item())\n",
    "        D_losses.append(errD.item())\n",
    "\n",
    "        # Check how the generator is doing by saving G's output on fixed_noise\n",
    "        if (iters % 8 == 0) or ((epoch == num_epochs-1) and (i == len(dataloader)-1)):\n",
    "            with torch.no_grad():\n",
    "                fake = netG(fixed_noise, real_label_from_data).detach().cpu()   # Move back to CPU so it can be used.\n",
    "            \n",
    "            output_list.append(fake)\n",
    "\n",
    "        iters += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.title(\"Generator and Discriminator Loss During Training\")\n",
    "plt.plot(G_losses,label=\"G\")\n",
    "plt.plot(D_losses,label=\"D\")\n",
    "plt.xlabel(\"iterations\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

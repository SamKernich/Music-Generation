{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model utilizes a DCGAN architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import music21\n",
    "import matplotlib as plt\n",
    "\n",
    "\n",
    "import torch.backends.cudnn as cudnn\n",
    "torch.cuda.empty_cache()\n",
    "cudnn.benchmark = True  # Optimise for hardware\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "EPOCHS = 100\n",
    "NOISE_DIM = 100\n",
    "NUM_CLASSES = 18\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 128, 256])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, latent_dim, num_classes):\n",
    "        super(Generator, self).__init__()\n",
    "\n",
    "        # Embedding for the labels (num_classes = 18 for each composer)\n",
    "        self.label_emb = nn.Embedding(num_classes, 50)  # (N, 50)\n",
    "\n",
    "        # Dense layer for the label embedding\n",
    "        self.fc_label = nn.Linear(50, 8 * 16)  # (N, 128) for reshaping to 8x16\n",
    "\n",
    "        # Dense layer for the latent noise input\n",
    "        self.fc_noise = nn.Linear(latent_dim, 128 * 8 * 16)  # (N, 128 * 8 * 16)\n",
    "\n",
    "        # ConvTranspose layers for upsampling\n",
    "        self.conv1 = nn.ConvTranspose2d(129, 128, kernel_size=4, stride=2, padding=1)  # Upsample to 16x32\n",
    "        self.conv2 = nn.ConvTranspose2d(128, 64, kernel_size=4, stride=2, padding=1)   # Upsample to 32x64\n",
    "        self.conv3 = nn.ConvTranspose2d(64, 32, kernel_size=4, stride=2, padding=1)    # Upsample to 64x128\n",
    "        self.conv4 = nn.ConvTranspose2d(32, 1, kernel_size=4, stride=2, padding=1)     # Upsample to 128x256\n",
    "\n",
    "        # LeakyReLU activation function\n",
    "        self.activation = nn.LeakyReLU(0.2)\n",
    "\n",
    "    def forward(self, noise, labels):\n",
    "        # Step 1: Embed the labels\n",
    "        label_embedding = self.label_emb(labels)  # (N, 50)\n",
    "        label_embedding = self.fc_label(label_embedding)  # (N, 128)\n",
    "        label_embedding = label_embedding.view(-1, 8, 16, 1)  # Reshape to (N, 8, 16, 1)\n",
    "\n",
    "        # Step 2: Process the latent noise input through a dense layer\n",
    "        noise_embedding = self.fc_noise(noise)  # (N, 128 * 8 * 16)\n",
    "        noise_embedding = self.activation(noise_embedding)  # Apply LeakyReLU\n",
    "        noise_embedding = noise_embedding.view(-1, 128, 8, 16)  # Reshape to (N, 128, 8, 16)\n",
    "\n",
    "        # Step 3: Concatenate the noise and label embeddings along the channel axis\n",
    "        x = torch.cat((noise_embedding, label_embedding.permute(0, 3, 1, 2)), dim=1)  # (N, 129, 8, 16)\n",
    "\n",
    "        # Step 4: Upsample to 16x32\n",
    "        x = self.conv1(x)  # (N, 128, 16, 32)\n",
    "        x = self.activation(x)\n",
    "\n",
    "        # Step 5: Upsample to 32x64\n",
    "        x = self.conv2(x)  # (N, 64, 32, 64)\n",
    "        x = self.activation(x)\n",
    "\n",
    "        # Step 6: Upsample to 64x128\n",
    "        x = self.conv3(x)  # (N, 32, 64, 128)\n",
    "        x = self.activation(x)\n",
    "\n",
    "        # Step 7: Upsample to 128x256\n",
    "        out = self.conv4(x)  # (N, 1, 128, 256)\n",
    "        out = torch.sigmoid(out)\n",
    "\n",
    "         # Step 9: Apply thresholding to get binary output (0 or 1)\n",
    "        out_binary = (out > 0.5).float()  # Convert to 0 or 1\n",
    "\n",
    "        return out_binary\n",
    "\n",
    "# Instantiate the model\n",
    "latent_dim = 100\n",
    "num_classes = 10\n",
    "model = Generator(latent_dim, num_classes)\n",
    "\n",
    "# Example input (noise and labels)\n",
    "batch_size = 1\n",
    "noise = torch.randn(batch_size, latent_dim)  # (N, latent_dim)\n",
    "labels = torch.randint(0, num_classes, (batch_size,))  # (N,)\n",
    "\n",
    "# Forward pass\n",
    "output = model(noise, labels)\n",
    "print(output.shape)  # Should be (batch_size, 1, 128, 256)\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1])\n",
      "tensor([[0.5062]], grad_fn=<SigmoidBackward0>)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, in_shape=(1, 128, 256), num_classes=10):\n",
    "        super(Discriminator, self).__init__()\n",
    "        \n",
    "        # Embedding for labels\n",
    "        self.label_emb = nn.Embedding(num_classes, 50)  # (N, 50)\n",
    "        \n",
    "        # Fully connected layer for label embedding, to match pianoroll matrix size\n",
    "        self.fc_label = nn.Linear(50, in_shape[1] * in_shape[2])  # (N, 128 * 256)\n",
    "        \n",
    "        # Convolutional layers for processing the concatenated image and label\n",
    "        self.conv1 = nn.Conv2d(2, 128, kernel_size=3, stride=2, padding=1)  # (N, 128, 64, 128)\n",
    "        self.conv2 = nn.Conv2d(128, 128, kernel_size=3, stride=2, padding=1)  # (N, 128, 32, 64)\n",
    "        \n",
    "        # Dropout layer for regularization\n",
    "        self.dropout = nn.Dropout(0.4)\n",
    "        \n",
    "        # Fully connected output layer\n",
    "        self.fc = nn.Linear(128 * 32 * 64, 1)\n",
    "        \n",
    "        # Sigmoid activation function\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, img, labels):\n",
    "        # Step 1: Embed the labels\n",
    "        label_embedding = self.label_emb(labels)  # (N, 50)\n",
    "        \n",
    "        # Step 2: Process label embedding through a dense layer to match image dimensions\n",
    "        label_embedding = self.fc_label(label_embedding)  # (N, 128 * 256)\n",
    "        \n",
    "        # Step 3: Reshape label embedding to add as a channel to the image\n",
    "        label_embedding = label_embedding.view(-1, 1, 128, 256)  # Reshape to (N, 1, 128, 256)\n",
    "        \n",
    "        # Step 4: Concatenate the label embedding with the image input\n",
    "        x = torch.cat((img, label_embedding), dim=1)  # Concatenate along channel dimension: (N, 2, 128, 256)\n",
    "        \n",
    "        # Step 5: Apply convolutional layers to process the image and label\n",
    "        x = nn.LeakyReLU(0.2)(self.conv1(x))  # (N, 128, 64, 128)\n",
    "        x = nn.LeakyReLU(0.2)(self.conv2(x))  # (N, 128, 32, 64)\n",
    "        \n",
    "        # Step 6: Flatten the feature maps\n",
    "        x = x.view(x.size(0), -1)  # (N, 128 * 32 * 64 = 262144)\n",
    "        \n",
    "        # Step 7: Apply dropout for regularization\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        # Step 8: Fully connected layer and sigmoid activation for binary classification\n",
    "        out = self.fc(x)  # (N, 1)\n",
    "        out = self.sigmoid(out)  # Sigmoid activation to get values between 0 and 1\n",
    "        \n",
    "        return out\n",
    "\n",
    "# Instantiate the discriminator\n",
    "discriminator = Discriminator(in_shape=(1, 128, 256), num_classes=10)\n",
    "\n",
    "\n",
    "# Example inputs: random image and label\n",
    "batch_size = 1\n",
    "image = torch.randn(batch_size, 1, 128, 256)  # Random image input\n",
    "#labels = torch.randint(0, 10, (batch_size,))  # Random labels (10 classes)\n",
    "\n",
    "# Forward pass\n",
    "output1 = discriminator(output, labels)\n",
    "\n",
    "print(output1.shape)  # Output should be (batch_size, 1)\n",
    "print(output1)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Music_gen_WS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
